{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f775d47e",
   "metadata": {},
   "source": [
    "## Image Processing Basics\n",
    "\n",
    "Install OpenCV and NumPy:\n",
    "\n",
    "```bash\n",
    "pip install opencv-python numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44dc14f",
   "metadata": {},
   "source": [
    "### Import the basics modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c69c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dab096",
   "metadata": {},
   "source": [
    "### Loading and Displaying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e6fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../human_faces_and_object_dataset/Images/male_faces/male_913.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b92cf",
   "metadata": {},
   "source": [
    "### Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8754be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image Window', image)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d073a",
   "metadata": {},
   "source": [
    "### Check image shape\n",
    "\n",
    "What Is image.shape?\n",
    "It tells you the dimensions of the image as a NumPy array.\n",
    "\n",
    "For a color image:\n",
    "\n",
    "```python\n",
    "(height, width, channels) = image.shape\n",
    "```\n",
    "\n",
    "- height – number of rows (pixels from top to bottom)\n",
    "\n",
    "- width – number of columns (pixels from left to right)\n",
    "\n",
    "- channels – number of color channels:\n",
    "\n",
    "3 for BGR (Blue, Green, Red) — OpenCV uses BGR instead of RGB\n",
    "\n",
    "4 if the image has an alpha channel (transparency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b45859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 433, 3)\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)  # Output: (height, width, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd065034",
   "metadata": {},
   "source": [
    "### Convert BGR to Grayscale:\n",
    "\n",
    "Why Convert to Grayscale?\n",
    "\n",
    "   - A grayscale image has only one channel (instead of 3), where each pixel represents intensity (brightness) from black (0) to white (255).\n",
    "\n",
    "   - It simplifies many computer vision tasks, like edge detection or face detection, because it reduces complexity.\n",
    "\n",
    "   - Many algorithms work faster on grayscale images.\n",
    "\n",
    "\n",
    "What Does This Mean in Practice?\n",
    "   - image is a 3D array with shape (height, width, 3).\n",
    "\n",
    "   - gray becomes a 2D array with shape (height, width).\n",
    "\n",
    "   - Each pixel in gray is a single number representing brightness.\n",
    "\n",
    "    Example:\n",
    "    If your original pixel at [100, 150] is:\n",
    "    [52, 100, 150]  # (B=52, G=100, R=150)\n",
    "\n",
    "    After grayscale conversion, it might become:\n",
    "    120  # Intensity value (a weighted sum of B, G, R)\n",
    "\n",
    "(OpenCV uses a specific formula to compute this weighted sum that approximates human perception.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81776c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 433)\n"
     ]
    }
   ],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(gray.shape) # There's no 3rd value because it's just one channel — intensity (0–255).\n",
    "\n",
    "cv2.imshow('Image Window', gray)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26308972",
   "metadata": {},
   "source": [
    "### Basic Color Conversions\n",
    "\n",
    "| From → To   | Flag                  | Description                                      |\n",
    "| ----------- | --------------------- | ------------------------------------------------ |\n",
    "| BGR → Gray  | `cv2.COLOR_BGR2GRAY`  | Convert to grayscale                             |\n",
    "| BGR → RGB   | `cv2.COLOR_BGR2RGB`   | Reorder channels (Blue to Red)                   |\n",
    "| BGR → HSV   | `cv2.COLOR_BGR2HSV`   | Hue-Saturation-Value (great for color filtering) |\n",
    "| BGR → LAB   | `cv2.COLOR_BGR2LAB`   | Lightness, a, b (used in color science)          |\n",
    "| BGR → YCrCb | `cv2.COLOR_BGR2YCrCb` | Luma + Chroma (used in video codecs)             |\n",
    "| BGR → XYZ   | `cv2.COLOR_BGR2XYZ`   | Used in color management                         |\n",
    "\n",
    "\n",
    "Why Use Different Color Spaces?\n",
    "    Grayscale: For edge detection, face detection, thresholding.\n",
    "\n",
    "    HSV: More intuitive for color filtering (e.g., detecting a red object).\n",
    "\n",
    "    LAB/YCrCb: Used in advanced color correction, skin tone detection, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c1163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COLOR_BAYER_BG2BGR', 'COLOR_BAYER_BG2BGRA', 'COLOR_BAYER_BG2BGR_EA', 'COLOR_BAYER_BG2BGR_VNG', 'COLOR_BAYER_BG2GRAY', 'COLOR_BAYER_BG2RGB', 'COLOR_BAYER_BG2RGBA', 'COLOR_BAYER_BG2RGB_EA', 'COLOR_BAYER_BG2RGB_VNG', 'COLOR_BAYER_BGGR2BGR', 'COLOR_BAYER_BGGR2BGRA', 'COLOR_BAYER_BGGR2BGR_EA', 'COLOR_BAYER_BGGR2BGR_VNG', 'COLOR_BAYER_BGGR2GRAY', 'COLOR_BAYER_BGGR2RGB', 'COLOR_BAYER_BGGR2RGBA', 'COLOR_BAYER_BGGR2RGB_EA', 'COLOR_BAYER_BGGR2RGB_VNG', 'COLOR_BAYER_GB2BGR', 'COLOR_BAYER_GB2BGRA', 'COLOR_BAYER_GB2BGR_EA', 'COLOR_BAYER_GB2BGR_VNG', 'COLOR_BAYER_GB2GRAY', 'COLOR_BAYER_GB2RGB', 'COLOR_BAYER_GB2RGBA', 'COLOR_BAYER_GB2RGB_EA', 'COLOR_BAYER_GB2RGB_VNG', 'COLOR_BAYER_GBRG2BGR', 'COLOR_BAYER_GBRG2BGRA', 'COLOR_BAYER_GBRG2BGR_EA', 'COLOR_BAYER_GBRG2BGR_VNG', 'COLOR_BAYER_GBRG2GRAY', 'COLOR_BAYER_GBRG2RGB', 'COLOR_BAYER_GBRG2RGBA', 'COLOR_BAYER_GBRG2RGB_EA', 'COLOR_BAYER_GBRG2RGB_VNG', 'COLOR_BAYER_GR2BGR', 'COLOR_BAYER_GR2BGRA', 'COLOR_BAYER_GR2BGR_EA', 'COLOR_BAYER_GR2BGR_VNG', 'COLOR_BAYER_GR2GRAY', 'COLOR_BAYER_GR2RGB', 'COLOR_BAYER_GR2RGBA', 'COLOR_BAYER_GR2RGB_EA', 'COLOR_BAYER_GR2RGB_VNG', 'COLOR_BAYER_GRBG2BGR', 'COLOR_BAYER_GRBG2BGRA', 'COLOR_BAYER_GRBG2BGR_EA', 'COLOR_BAYER_GRBG2BGR_VNG', 'COLOR_BAYER_GRBG2GRAY', 'COLOR_BAYER_GRBG2RGB', 'COLOR_BAYER_GRBG2RGBA', 'COLOR_BAYER_GRBG2RGB_EA', 'COLOR_BAYER_GRBG2RGB_VNG', 'COLOR_BAYER_RG2BGR', 'COLOR_BAYER_RG2BGRA', 'COLOR_BAYER_RG2BGR_EA', 'COLOR_BAYER_RG2BGR_VNG', 'COLOR_BAYER_RG2GRAY', 'COLOR_BAYER_RG2RGB', 'COLOR_BAYER_RG2RGBA', 'COLOR_BAYER_RG2RGB_EA', 'COLOR_BAYER_RG2RGB_VNG', 'COLOR_BAYER_RGGB2BGR', 'COLOR_BAYER_RGGB2BGRA', 'COLOR_BAYER_RGGB2BGR_EA', 'COLOR_BAYER_RGGB2BGR_VNG', 'COLOR_BAYER_RGGB2GRAY', 'COLOR_BAYER_RGGB2RGB', 'COLOR_BAYER_RGGB2RGBA', 'COLOR_BAYER_RGGB2RGB_EA', 'COLOR_BAYER_RGGB2RGB_VNG', 'COLOR_BGR2BGR555', 'COLOR_BGR2BGR565', 'COLOR_BGR2BGRA', 'COLOR_BGR2GRAY', 'COLOR_BGR2HLS', 'COLOR_BGR2HLS_FULL', 'COLOR_BGR2HSV', 'COLOR_BGR2HSV_FULL', 'COLOR_BGR2LAB', 'COLOR_BGR2LUV', 'COLOR_BGR2Lab', 'COLOR_BGR2Luv', 'COLOR_BGR2RGB', 'COLOR_BGR2RGBA', 'COLOR_BGR2XYZ', 'COLOR_BGR2YCR_CB', 'COLOR_BGR2YCrCb', 'COLOR_BGR2YUV', 'COLOR_BGR2YUV_I420', 'COLOR_BGR2YUV_IYUV', 'COLOR_BGR2YUV_UYNV', 'COLOR_BGR2YUV_UYVY', 'COLOR_BGR2YUV_Y422', 'COLOR_BGR2YUV_YUNV', 'COLOR_BGR2YUV_YUY2', 'COLOR_BGR2YUV_YUYV', 'COLOR_BGR2YUV_YV12', 'COLOR_BGR2YUV_YVYU', 'COLOR_BGR5552BGR', 'COLOR_BGR5552BGRA', 'COLOR_BGR5552GRAY', 'COLOR_BGR5552RGB', 'COLOR_BGR5552RGBA', 'COLOR_BGR5652BGR', 'COLOR_BGR5652BGRA', 'COLOR_BGR5652GRAY', 'COLOR_BGR5652RGB', 'COLOR_BGR5652RGBA', 'COLOR_BGRA2BGR', 'COLOR_BGRA2BGR555', 'COLOR_BGRA2BGR565', 'COLOR_BGRA2GRAY', 'COLOR_BGRA2RGB', 'COLOR_BGRA2RGBA', 'COLOR_BGRA2YUV_I420', 'COLOR_BGRA2YUV_IYUV', 'COLOR_BGRA2YUV_UYNV', 'COLOR_BGRA2YUV_UYVY', 'COLOR_BGRA2YUV_Y422', 'COLOR_BGRA2YUV_YUNV', 'COLOR_BGRA2YUV_YUY2', 'COLOR_BGRA2YUV_YUYV', 'COLOR_BGRA2YUV_YV12', 'COLOR_BGRA2YUV_YVYU', 'COLOR_BayerBG2BGR', 'COLOR_BayerBG2BGRA', 'COLOR_BayerBG2BGR_EA', 'COLOR_BayerBG2BGR_VNG', 'COLOR_BayerBG2GRAY', 'COLOR_BayerBG2RGB', 'COLOR_BayerBG2RGBA', 'COLOR_BayerBG2RGB_EA', 'COLOR_BayerBG2RGB_VNG', 'COLOR_BayerBGGR2BGR', 'COLOR_BayerBGGR2BGRA', 'COLOR_BayerBGGR2BGR_EA', 'COLOR_BayerBGGR2BGR_VNG', 'COLOR_BayerBGGR2GRAY', 'COLOR_BayerBGGR2RGB', 'COLOR_BayerBGGR2RGBA', 'COLOR_BayerBGGR2RGB_EA', 'COLOR_BayerBGGR2RGB_VNG', 'COLOR_BayerGB2BGR', 'COLOR_BayerGB2BGRA', 'COLOR_BayerGB2BGR_EA', 'COLOR_BayerGB2BGR_VNG', 'COLOR_BayerGB2GRAY', 'COLOR_BayerGB2RGB', 'COLOR_BayerGB2RGBA', 'COLOR_BayerGB2RGB_EA', 'COLOR_BayerGB2RGB_VNG', 'COLOR_BayerGBRG2BGR', 'COLOR_BayerGBRG2BGRA', 'COLOR_BayerGBRG2BGR_EA', 'COLOR_BayerGBRG2BGR_VNG', 'COLOR_BayerGBRG2GRAY', 'COLOR_BayerGBRG2RGB', 'COLOR_BayerGBRG2RGBA', 'COLOR_BayerGBRG2RGB_EA', 'COLOR_BayerGBRG2RGB_VNG', 'COLOR_BayerGR2BGR', 'COLOR_BayerGR2BGRA', 'COLOR_BayerGR2BGR_EA', 'COLOR_BayerGR2BGR_VNG', 'COLOR_BayerGR2GRAY', 'COLOR_BayerGR2RGB', 'COLOR_BayerGR2RGBA', 'COLOR_BayerGR2RGB_EA', 'COLOR_BayerGR2RGB_VNG', 'COLOR_BayerGRBG2BGR', 'COLOR_BayerGRBG2BGRA', 'COLOR_BayerGRBG2BGR_EA', 'COLOR_BayerGRBG2BGR_VNG', 'COLOR_BayerGRBG2GRAY', 'COLOR_BayerGRBG2RGB', 'COLOR_BayerGRBG2RGBA', 'COLOR_BayerGRBG2RGB_EA', 'COLOR_BayerGRBG2RGB_VNG', 'COLOR_BayerRG2BGR', 'COLOR_BayerRG2BGRA', 'COLOR_BayerRG2BGR_EA', 'COLOR_BayerRG2BGR_VNG', 'COLOR_BayerRG2GRAY', 'COLOR_BayerRG2RGB', 'COLOR_BayerRG2RGBA', 'COLOR_BayerRG2RGB_EA', 'COLOR_BayerRG2RGB_VNG', 'COLOR_BayerRGGB2BGR', 'COLOR_BayerRGGB2BGRA', 'COLOR_BayerRGGB2BGR_EA', 'COLOR_BayerRGGB2BGR_VNG', 'COLOR_BayerRGGB2GRAY', 'COLOR_BayerRGGB2RGB', 'COLOR_BayerRGGB2RGBA', 'COLOR_BayerRGGB2RGB_EA', 'COLOR_BayerRGGB2RGB_VNG', 'COLOR_COLORCVT_MAX', 'COLOR_GRAY2BGR', 'COLOR_GRAY2BGR555', 'COLOR_GRAY2BGR565', 'COLOR_GRAY2BGRA', 'COLOR_GRAY2RGB', 'COLOR_GRAY2RGBA', 'COLOR_HLS2BGR', 'COLOR_HLS2BGR_FULL', 'COLOR_HLS2RGB', 'COLOR_HLS2RGB_FULL', 'COLOR_HSV2BGR', 'COLOR_HSV2BGR_FULL', 'COLOR_HSV2RGB', 'COLOR_HSV2RGB_FULL', 'COLOR_LAB2BGR', 'COLOR_LAB2LBGR', 'COLOR_LAB2LRGB', 'COLOR_LAB2RGB', 'COLOR_LBGR2LAB', 'COLOR_LBGR2LUV', 'COLOR_LBGR2Lab', 'COLOR_LBGR2Luv', 'COLOR_LRGB2LAB', 'COLOR_LRGB2LUV', 'COLOR_LRGB2Lab', 'COLOR_LRGB2Luv', 'COLOR_LUV2BGR', 'COLOR_LUV2LBGR', 'COLOR_LUV2LRGB', 'COLOR_LUV2RGB', 'COLOR_Lab2BGR', 'COLOR_Lab2LBGR', 'COLOR_Lab2LRGB', 'COLOR_Lab2RGB', 'COLOR_Luv2BGR', 'COLOR_Luv2LBGR', 'COLOR_Luv2LRGB', 'COLOR_Luv2RGB', 'COLOR_M_RGBA2RGBA', 'COLOR_RGB2BGR', 'COLOR_RGB2BGR555', 'COLOR_RGB2BGR565', 'COLOR_RGB2BGRA', 'COLOR_RGB2GRAY', 'COLOR_RGB2HLS', 'COLOR_RGB2HLS_FULL', 'COLOR_RGB2HSV', 'COLOR_RGB2HSV_FULL', 'COLOR_RGB2LAB', 'COLOR_RGB2LUV', 'COLOR_RGB2Lab', 'COLOR_RGB2Luv', 'COLOR_RGB2RGBA', 'COLOR_RGB2XYZ', 'COLOR_RGB2YCR_CB', 'COLOR_RGB2YCrCb', 'COLOR_RGB2YUV', 'COLOR_RGB2YUV_I420', 'COLOR_RGB2YUV_IYUV', 'COLOR_RGB2YUV_UYNV', 'COLOR_RGB2YUV_UYVY', 'COLOR_RGB2YUV_Y422', 'COLOR_RGB2YUV_YUNV', 'COLOR_RGB2YUV_YUY2', 'COLOR_RGB2YUV_YUYV', 'COLOR_RGB2YUV_YV12', 'COLOR_RGB2YUV_YVYU', 'COLOR_RGBA2BGR', 'COLOR_RGBA2BGR555', 'COLOR_RGBA2BGR565', 'COLOR_RGBA2BGRA', 'COLOR_RGBA2GRAY', 'COLOR_RGBA2M_RGBA', 'COLOR_RGBA2RGB', 'COLOR_RGBA2YUV_I420', 'COLOR_RGBA2YUV_IYUV', 'COLOR_RGBA2YUV_UYNV', 'COLOR_RGBA2YUV_UYVY', 'COLOR_RGBA2YUV_Y422', 'COLOR_RGBA2YUV_YUNV', 'COLOR_RGBA2YUV_YUY2', 'COLOR_RGBA2YUV_YUYV', 'COLOR_RGBA2YUV_YV12', 'COLOR_RGBA2YUV_YVYU', 'COLOR_RGBA2mRGBA', 'COLOR_XYZ2BGR', 'COLOR_XYZ2RGB', 'COLOR_YCR_CB2BGR', 'COLOR_YCR_CB2RGB', 'COLOR_YCrCb2BGR', 'COLOR_YCrCb2RGB', 'COLOR_YUV2BGR', 'COLOR_YUV2BGRA_I420', 'COLOR_YUV2BGRA_IYUV', 'COLOR_YUV2BGRA_NV12', 'COLOR_YUV2BGRA_NV21', 'COLOR_YUV2BGRA_UYNV', 'COLOR_YUV2BGRA_UYVY', 'COLOR_YUV2BGRA_Y422', 'COLOR_YUV2BGRA_YUNV', 'COLOR_YUV2BGRA_YUY2', 'COLOR_YUV2BGRA_YUYV', 'COLOR_YUV2BGRA_YV12', 'COLOR_YUV2BGRA_YVYU', 'COLOR_YUV2BGR_I420', 'COLOR_YUV2BGR_IYUV', 'COLOR_YUV2BGR_NV12', 'COLOR_YUV2BGR_NV21', 'COLOR_YUV2BGR_UYNV', 'COLOR_YUV2BGR_UYVY', 'COLOR_YUV2BGR_Y422', 'COLOR_YUV2BGR_YUNV', 'COLOR_YUV2BGR_YUY2', 'COLOR_YUV2BGR_YUYV', 'COLOR_YUV2BGR_YV12', 'COLOR_YUV2BGR_YVYU', 'COLOR_YUV2GRAY_420', 'COLOR_YUV2GRAY_I420', 'COLOR_YUV2GRAY_IYUV', 'COLOR_YUV2GRAY_NV12', 'COLOR_YUV2GRAY_NV21', 'COLOR_YUV2GRAY_UYNV', 'COLOR_YUV2GRAY_UYVY', 'COLOR_YUV2GRAY_Y422', 'COLOR_YUV2GRAY_YUNV', 'COLOR_YUV2GRAY_YUY2', 'COLOR_YUV2GRAY_YUYV', 'COLOR_YUV2GRAY_YV12', 'COLOR_YUV2GRAY_YVYU', 'COLOR_YUV2RGB', 'COLOR_YUV2RGBA_I420', 'COLOR_YUV2RGBA_IYUV', 'COLOR_YUV2RGBA_NV12', 'COLOR_YUV2RGBA_NV21', 'COLOR_YUV2RGBA_UYNV', 'COLOR_YUV2RGBA_UYVY', 'COLOR_YUV2RGBA_Y422', 'COLOR_YUV2RGBA_YUNV', 'COLOR_YUV2RGBA_YUY2', 'COLOR_YUV2RGBA_YUYV', 'COLOR_YUV2RGBA_YV12', 'COLOR_YUV2RGBA_YVYU', 'COLOR_YUV2RGB_I420', 'COLOR_YUV2RGB_IYUV', 'COLOR_YUV2RGB_NV12', 'COLOR_YUV2RGB_NV21', 'COLOR_YUV2RGB_UYNV', 'COLOR_YUV2RGB_UYVY', 'COLOR_YUV2RGB_Y422', 'COLOR_YUV2RGB_YUNV', 'COLOR_YUV2RGB_YUY2', 'COLOR_YUV2RGB_YUYV', 'COLOR_YUV2RGB_YV12', 'COLOR_YUV2RGB_YVYU', 'COLOR_YUV420P2BGR', 'COLOR_YUV420P2BGRA', 'COLOR_YUV420P2GRAY', 'COLOR_YUV420P2RGB', 'COLOR_YUV420P2RGBA', 'COLOR_YUV420SP2BGR', 'COLOR_YUV420SP2BGRA', 'COLOR_YUV420SP2GRAY', 'COLOR_YUV420SP2RGB', 'COLOR_YUV420SP2RGBA', 'COLOR_YUV420p2BGR', 'COLOR_YUV420p2BGRA', 'COLOR_YUV420p2GRAY', 'COLOR_YUV420p2RGB', 'COLOR_YUV420p2RGBA', 'COLOR_YUV420sp2BGR', 'COLOR_YUV420sp2BGRA', 'COLOR_YUV420sp2GRAY', 'COLOR_YUV420sp2RGB', 'COLOR_YUV420sp2RGBA', 'COLOR_mRGBA2RGBA']\n"
     ]
    }
   ],
   "source": [
    "#To view all available flags in code:\n",
    "\n",
    "flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "print(flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39fb4e",
   "metadata": {},
   "source": [
    "### Split channels (B, G, R):\n",
    "\n",
    "This line is splitting a color image into its individual color channels:\n",
    "\n",
    "- b → the Blue channel\n",
    "\n",
    "- g → the Green channel\n",
    "\n",
    "- r → the Red channel\n",
    "\n",
    "Each of these is a 2D array (grayscale-like), containing intensity values (0–255) for that channel across the entire image.\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "| Use Case                 | What You Do                       |\n",
    "| ------------------------ | --------------------------------- |\n",
    "| Detect red traffic signs | Analyze the red channel only      |\n",
    "| Remove a tint from image | Zero out the blue channel         |\n",
    "| Highlight vegetation     | Focus on the green channel        |\n",
    "| Channel-wise histogram   | Compare intensities across colors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02bea365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue channel shape: (650, 433)\n",
      "Green channel shape: (650, 433)\n",
      "Red channel shape: (650, 433)\n"
     ]
    }
   ],
   "source": [
    "b, g, r = cv2.split(image)\n",
    "\n",
    "print(f\"Blue channel shape: {b.shape}\")\n",
    "print(f\"Green channel shape: {g.shape}\")\n",
    "print(f\"Red channel shape: {r.shape}\")\n",
    "\n",
    "cv2.imshow('B Image Window', b)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('G Image Window', g)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('R Image Window', r)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a825cbd9",
   "metadata": {},
   "source": [
    "### Merge channels:\n",
    "\n",
    "Imagine you want to reduce the red in an image:\n",
    "\n",
    "```python\n",
    "b, g, r = cv2.split(image)\n",
    "r[:] = 0  # remove all red\n",
    "new_image = cv2.merge((b, g, r))\n",
    "```\n",
    "\n",
    "Now you’ve created a new image with no red, and you need to merge it back to get a proper 3-channel image again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e42913",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = cv2.merge((b, g, r))\n",
    "\n",
    "cv2.imshow('Merged BGR Image Window', merged)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59118dba",
   "metadata": {},
   "source": [
    "### Basic Operations\n",
    "#### 1. Resize image\n",
    "\n",
    "Syntax:\n",
    "\n",
    "``` python\n",
    "resized = cv2.resize(src, dsize, interpolation)\n",
    "```\n",
    "\n",
    "- src – original image\n",
    "\n",
    "- dsize – output size as a tuple (width, height)\n",
    "\n",
    "- interpolation – algorithm used to estimate pixel values\n",
    "\n",
    "##### Interpolation Methods (Pixel Estimation)\n",
    "Interpolation is how OpenCV fills in pixel values when resizing.\n",
    "\n",
    "| Method           | OpenCV Flag          | Use When...                   |\n",
    "| ---------------- | -------------------- | ----------------------------- |\n",
    "| Nearest neighbor | `cv2.INTER_NEAREST`  | Fast, low-quality             |\n",
    "| Bilinear         | `cv2.INTER_LINEAR`   | Good for upscaling (default)  |\n",
    "| Bicubic          | `cv2.INTER_CUBIC`    | Better quality, slower        |\n",
    "| Lanczos          | `cv2.INTER_LANCZOS4` | High-quality downscaling      |\n",
    "| Area-based       | `cv2.INTER_AREA`     | Best for **shrinking images** |\n",
    "\n",
    "\n",
    "Aspect Ratio: Watch Out!\n",
    "\n",
    "If you stretch the image unevenly, you'll distort it.\n",
    "\n",
    "❌ Bad (distorted):\n",
    "``` python\n",
    "resized = cv2.resize(image, (500, 100))  # Wrong aspect ratio\n",
    "```\n",
    "\n",
    "✅ Good (maintain aspect ratio):\n",
    "```python\n",
    "scale = 0.5  # 50% smaller\n",
    "width = int(image.shape[1] * scale)\n",
    "height = int(image.shape[0] * scale)\n",
    "resized = cv2.resize(image, (width, height))\n",
    "````\n",
    "\n",
    " Summary\n",
    "\n",
    "| Concept              | Code Example                                |\n",
    "| -------------------- | ------------------------------------------- |\n",
    "| Resize to fixed size | `cv2.resize(image, (300, 300))`             |\n",
    "| Resize by scale      | `cv2.resize(image, (w//2, h//2))`           |\n",
    "| Maintain aspect      | Calculate new width/height proportionally   |\n",
    "| Shrink               | Use `cv2.INTER_AREA`                        |\n",
    "| Enlarge              | Use `cv2.INTER_LINEAR` or `cv2.INTER_CUBIC` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.resize(image, (300, 300))\n",
    "# resized = cv2.resize(image, (300, 300),cv2.INTER_CUBIC)\n",
    "cv2.imshow('Resized Image Window', resized)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33daade4",
   "metadata": {},
   "source": [
    "#### 2. Crop image\n",
    "\n",
    "Cropping is just array slicing in NumPy!\n",
    "\n",
    "```python\n",
    "    cropped = image[startY:endY, startX:endX]\n",
    "```\n",
    "\n",
    "Safe Cropping Tips\n",
    "✅ Always check your bounds:\n",
    "\n",
    "\n",
    "```python\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    x1, y1, x2, y2 = 100, 50, 400, 200\n",
    "\n",
    "    # Ensure x2 < width, y2 < height\n",
    "    x2 = min(x2, width)\n",
    "    y2 = min(y2, height)\n",
    "\n",
    "    cropped = image[y1:y2, x1:x2]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = image[50:200, 100:300] # [y1:y2, x1:x2]\n",
    "\n",
    "cv2.imshow('Cropped BGR Image Window', cropped)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60625fe9",
   "metadata": {},
   "source": [
    "#### 3. Draw shapes and text\n",
    "\n",
    "OpenCV has built-in functions for drawing shapes and text directly onto images, using pixel coordinates\n",
    "\n",
    "| What to Draw | Function          |\n",
    "| ------------ | ----------------- |\n",
    "| Line         | `cv2.line()`      |\n",
    "| Rectangle    | `cv2.rectangle()` |\n",
    "| Circle       | `cv2.circle()`    |\n",
    "| Ellipse      | `cv2.ellipse()`   |\n",
    "| Polygon      | `cv2.polylines()` |\n",
    "| Filled Shape | `thickness = -1`  |\n",
    "| Text         | `cv2.putText()`   |\n",
    "\n",
    "NOTE: All drawing is done in-place — i.e., it directly modifies the image you pass to the function.\n",
    "\n",
    "\n",
    "Coordinate System Reminder:\n",
    "Images are matrices:\n",
    "\n",
    "``` sql\n",
    "(0,0) ------------> x (columns)\n",
    "  |\n",
    "  |\n",
    "  ↓\n",
    "  y (rows)\n",
    "```\n",
    "Every shape is drawn based on (x, y) pixel positions.\n",
    "1. Line\n",
    "``` python\n",
    "cv2.line(img, pt1, pt2, color, thickness)\n",
    "cv2.line(image, (100, 50), (400, 300), (0, 255, 0), 3)  # Green line\n",
    "```\n",
    "\n",
    "2. Rectangle\n",
    "``` python\n",
    "cv2.rectangle(img, pt1, pt2, color, thickness)\n",
    "cv2.rectangle(image, (50, 50), (200, 200), (255, 0, 0), 2)  # Blue rectangle\n",
    "```\n",
    "\n",
    "3. Circle\n",
    "```python\n",
    "cv2.circle(img, center, radius, color, thickness)\n",
    "cv2.circle(image, (250, 250), 75, (0, 0, 255), -1)  # Filled red circle\n",
    "```\n",
    "\n",
    "4. Ellipse\n",
    "```python\n",
    "cv2.ellipse(img, center, axes, angle, startAngle, endAngle, color, thickness)\n",
    "cv2.ellipse(image, (300, 300), (100, 50), 0, 0, 360, (255, 255, 0), 2)\n",
    "```\n",
    "\n",
    "5. Text\n",
    "```python\n",
    "cv2.putText(img, text, org, font, fontScale, color, thickness, lineType)\n",
    "cv2.putText(image, \"Hello World!\", (50, 400), cv2.FONT_HERSHEY_SIMPLEX,1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "```\n",
    "\n",
    "###### Pro Tips\n",
    "- All colors are in BGR format (not RGB) ---if you havent converted.\n",
    "\n",
    "- Use cv2.lineType=cv2.LINE_AA for anti-aliased (smooth) lines.\n",
    "\n",
    "- To preserve the original image, draw on a copy:\n",
    "```python\n",
    "  copy_image = image.copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "921b7c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(image, (50, 50), (200, 200), (0, 255, 0), 2)  # Green box\n",
    "cv2.circle(image, (100, 100), 50, (255, 0, 0), 3)           # Blue circle\n",
    "cv2.putText(image, 'Hello', (50, 300), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('Shapes and Text Image Window', image)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda69a4",
   "metadata": {},
   "source": [
    "### Rotate and Flip\n",
    "#### 1. Rotate (90 degrees clockwise)\n",
    "\n",
    "```python\n",
    "cv2.rotate(image, flag)\n",
    "```\n",
    "| Rotation          | Flag                             |\n",
    "| ----------------- | -------------------------------- |\n",
    "| 90° Clockwise     | `cv2.ROTATE_90_CLOCKWISE`        |\n",
    "| 90° Counter-Clock | `cv2.ROTATE_90_COUNTERCLOCKWISE` |\n",
    "| 180°              | `cv2.ROTATE_180`                 |\n",
    "\n",
    "Example\n",
    "```python\n",
    "rotated = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "```\n",
    "Rotate by Arbitrary Angle\n",
    "For any angle (e.g., 45°, 30°, etc.):\n",
    "\n",
    "```python\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "```\n",
    "\n",
    "| Parameter | Meaning                                         |\n",
    "| --------- | ----------------------------------------------- |\n",
    "| `angle`   | Angle in degrees (positive = counter-clockwise) |\n",
    "| `scale`   | 1.0 = original size, <1 = shrink, >1 = enlarge  |\n",
    "| `M`       | Rotation matrix                                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b09c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "cv2.imshow('Rotated Image Window', rotated)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc39864",
   "metadata": {},
   "source": [
    "#### 2. Flip horizontally\n",
    "\n",
    "FLIP an Image\n",
    "\n",
    "``` python\n",
    "    cv2.flip(image, flipCode)\n",
    "```\n",
    "\n",
    "| `flipCode` | Flip Direction                         |\n",
    "| ---------- | -------------------------------------- |\n",
    "| `0`        | Flip **vertically** (up/down)          |\n",
    "| `1`        | Flip **horizontally** (left/right)     |\n",
    "| `-1`       | Flip both axes (horizontal + vertical) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf78722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = cv2.flip(image, 1)  # 1 for horizontal, 0 for vertical\n",
    "cv2.imshow('Flipped Image Window', flipped)\n",
    "cv2.waitKey(0)  # Waits for any key to be pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e0152",
   "metadata": {},
   "source": [
    "#### 3. Accessing Pixel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8da7b0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel at (100, 150): [255   0   0]\n",
      "Blue channel value at (100, 150): 255\n"
     ]
    }
   ],
   "source": [
    "pixel = image[100, 150]  # Returns a list: [B, G, R]\n",
    "print(f\"Pixel at (100, 150): {pixel}\")\n",
    "pixel_value = image[100, 150, 0]  # Accessing the blue channel value\n",
    "print(f\"Blue channel value at (100, 150): {pixel_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7a4ef",
   "metadata": {},
   "source": [
    "#### 4. Modify a pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493bc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel at (100, 150): [255 255 255]\n",
      "Blue channel value at (100, 150): 255\n"
     ]
    }
   ],
   "source": [
    "image[100, 150] = [255, 255, 255]  # Set to white\n",
    "\n",
    "pixel = image[100, 150]  # Returns a list: [B, G, R]\n",
    "print(f\"Pixel at (100, 150): {pixel}\")\n",
    "pixel_value = image[100, 150, 0]  # Accessing the blue channel value\n",
    "print(f\"Blue channel value at (100, 150): {pixel_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39e263",
   "metadata": {},
   "source": [
    "💡 Quick Summary: Important OpenCV Functions\n",
    "\n",
    "| Function          | Description                        |\n",
    "| ----------------- | ---------------------------------- |\n",
    "| `cv2.imread()`    | Load image from file               |\n",
    "| `cv2.imshow()`    | Display image                      |\n",
    "| `cv2.cvtColor()`  | Convert color space                |\n",
    "| `cv2.resize()`    | Resize an image                    |\n",
    "| `cv2.rectangle()` | Draw a rectangle                   |\n",
    "| `cv2.putText()`   | Write text on image                |\n",
    "| `cv2.flip()`      | Flip image vertically/horizontally |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d3a6ba",
   "metadata": {},
   "source": [
    "Practice Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0acf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load and display image\n",
    "image = cv2.imread('../human_faces_and_object_dataset/Images/male_faces/male_913.jpg')\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "# Convert to grayscale and show\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Grayscale', gray)\n",
    "\n",
    "# Draw a rectangle and put text\n",
    "cv2.rectangle(image, (50, 50), (250, 250), (0, 255, 0), 2)\n",
    "cv2.putText(image, 'Face', (60, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('With Rectangle', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
